# -*- coding: utf-8 -*-
"""spectral_audioGen.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fDMqKuGj7mCD_FzxpklL-yOSdl-5BJVs
"""

from librosa.feature.utils import delta
import librosa
import librosa.display
import numpy as np


num_audio_files = 40


def comprehensive_matrix(df):
    # Initialize empty list to store feature vectors
    features = []

    for i in range(1, num_audio_files + 1):
        audio_files = f"/content/index_{i}.wav"

        # Load the audio file
        y, sr = librosa.load(audio_files, sr=None)

        # Extract MFCC features
        mfcc = librosa.feature.mfcc(y=y, n_mfcc=13, sr=sr)

        mfcc_mean = np.mean(mfcc, axis=1)
        mfcc_variance = np.var(mfcc, axis=1)
        mfcc_delta = librosa.feature.delta(mfcc)
        delta_mean = np.mean(mfcc_delta, axis=1)
        mfcc_delta_delta = librosa.feature.delta(mfcc, order=2)
        delta_delta_mean = np.mean(mfcc_delta_delta, axis=1)

        # Append the results to the respective lists
        feature_vector = np.concatenate((mfcc_mean, mfcc_variance, delta_mean, delta_delta_mean))

        features.append(feature_vector)

    # Convert the lists of feature vectors to a feature matrix
    comprehensive_matrix = np.array(features)

    return comprehensive_matrix



for i in range(1, num_audio_files + 1):
        audio_files = f"/content/index_{i}.wav"


# Call the function with the DataFrame as an argument
comprehensive_matrix = comprehensive_matrix(audio_files)

# Print the matrix
print("Comprehensive Matrix:")
print(comprehensive_matrix)

comprehensive_matrix.shape

!pip install scikit-learn
from sklearn.decomposition import PCA

import matplotlib.pyplot as plt


def scree_plot(comprehensive_matrix, num_components=None):

    # Perform PCA
    pca = PCA()
    pca.fit(comprehensive_matrix)

    explained_variace = np.cumsum(pca.explained_variance_ratio_)

    if num_components is not None:
        explained_variace = explained_variace[:num_components]

    # Plot the scree plot
    plt.plot(range(1, len(explained_variace) + 1), explained_variace, marker='o', linestyle='-')
    plt.xlabel('Principal Component Number')
    plt.ylabel('Eigenvalue')
    plt.title('Scree Plot')
    plt.grid()
    plt.show()


# To plot all components:
scree_plot(comprehensive_matrix)

def pca(comprehensive_matrix, num_components=None):

    # Initialize PCA
    pca = PCA(n_components=num_components,whiten = True)

    # Fit the PCA model to the data and transform the data
    reduced_features = pca.fit_transform(comprehensive_matrix)

    return reduced_features


# Call the function to run PCA on comprehensive matrix
reduced_matrix = pca(comprehensive_matrix, num_components=10)

# Print the matrix
print("Reduced Matrix:")
print(reduced_matrix)

reduced_matrix.shape

def total_variance(reduced_matrix):

    tv = np.trace(np.cov(reduced_matrix.T))

    return tv

def generalized_variance(reduced_matrix):

    gv = np.linalg.det(np.cov(reduced_matrix.T))

    return gv

!pip install umap-learn
import seaborn as sns

import umap

# Calculate UMAP embeddings for all the features
reducer = umap.UMAP(random_state=42)
embedding = reducer.fit_transform(reduced_matrix)


# Create a scatter plot of the UMAP embeddings with different colors for each class
sns.set(style='white', context='notebook', rc={'figure.figsize': (7, 5)})
palette = sns.color_palette("husl", as_cmap=True)

#class_names = ["train", "wind"]
# Filter UMAP embeddings for each class
#for class_name in class_names:
umap_embeddings_class = embedding
sns.scatterplot(x=umap_embeddings_class[:, 0], y=umap_embeddings_class[:, 1], palette=palette, label='class_name')

plt.title('UMAP Projection of Feature Data')
plt.legend()
plt.show()

result = total_variance(reduced_matrix)
print(f"total variance for train : {result}")


print('\n')
result = generalized_variance(reduced_matrix)
print(f"generalized_variance for train : {result}")